name: Complete Test Suite (UI + API)

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch: # Allow manual trigger

env:
  NODE_VERSION: 'lts/*'
  CI: true
  # API Testing Configuration
  API_BASE_URL: 'https://api.social-media-demo.com/v1'
  API_TIMEOUT: '30000'

jobs:
  playwright-tests:
    name: Playwright UI Tests (${{ matrix.project }})
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    strategy:
      fail-fast: false
      matrix:
        project: [track-a-instagram, track-b-mock]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium
        
      - name: Run Playwright tests for ${{ matrix.project }}
        id: playwright-tests
        run: npx playwright test --project=${{ matrix.project }}
        continue-on-error: true

      - name: Generate Test Summary for ${{ matrix.project }}
        if: always()
        run: |
          echo "## 🎭 Playwright Test Results - ${{ matrix.project }}" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ matrix.project }}" == "track-a-instagram" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ⚠️ Instagram Test Status" >> $GITHUB_STEP_SUMMARY
            echo "Instagram tests are **intentionally skipped in CI** due to:" >> $GITHUB_STEP_SUMMARY
            echo "- Active bot detection and blocking" >> $GITHUB_STEP_SUMMARY
            echo "- Rate limiting on CI IP addresses" >> $GITHUB_STEP_SUMMARY
            echo "- Terms of Service considerations" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "✅ **See Track B (mock-social-app) for full test coverage demonstration**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -f test-results/results.json ]; then
            echo "### Test Statistics" >> $GITHUB_STEP_SUMMARY
            node -e "
              const fs = require('fs');
              if (!fs.existsSync('./test-results/results.json')) {
                console.log('No results file found');
                process.exit(0);
              }
              
              const results = require('./test-results/results.json');
              const stats = { total: 0, passed: 0, failed: 0, skipped: 0, flaky: 0 };
              
              results.suites.forEach(suite => {
                suite.specs.forEach(spec => {
                  spec.tests.forEach(test => {
                    stats.total++;
                    const result = test.results[0];
                    if (result.status === 'passed') stats.passed++;
                    else if (result.status === 'failed') stats.failed++;
                    else if (result.status === 'skipped') stats.skipped++;
                    else if (result.status === 'flaky') stats.flaky++;
                  });
                });
              });
              
              console.log('| Metric | Count | Percentage |');
              console.log('|--------|-------|------------|');
              console.log(\`| ✅ Passed | \${stats.passed} | \${stats.total > 0 ? ((stats.passed/stats.total)*100).toFixed(1) : 0}% |\`);
              console.log(\`| ❌ Failed | \${stats.failed} | \${stats.total > 0 ? ((stats.failed/stats.total)*100).toFixed(1) : 0}% |\`);
              console.log(\`| ⚠️ Flaky | \${stats.flaky} | \${stats.total > 0 ? ((stats.flaky/stats.total)*100).toFixed(1) : 0}% |\`);
              console.log(\`| ⏭️ Skipped | \${stats.skipped} | \${stats.total > 0 ? ((stats.skipped/stats.total)*100).toFixed(1) : 0}% |\`);
              console.log(\`| 📊 **Total** | **\${stats.total}** | **100%** |\`);
              
              if (stats.failed > 0) {
                console.log('\\n### ❌ Failed Tests');
                results.suites.forEach(suite => {
                  suite.specs.forEach(spec => {
                    spec.tests.forEach(test => {
                      if (test.results[0].status === 'failed') {
                        console.log(\`- \${test.projectName}: \${spec.title}\`);
                      }
                    });
                  });
                });
              }
            " >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ No test results found for ${{ matrix.project }}" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📈 Detailed Report" >> $GITHUB_STEP_SUMMARY
          echo "View the full HTML report in the artifacts section below." >> $GITHUB_STEP_SUMMARY

      - name: Upload test results for ${{ matrix.project }}
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.project }}
          path: |
            playwright-report/
            test-results/
            allure-results/
          retention-days: 14

  api-tests:
    name: API Tests (Postman/Newman)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [playwright-tests] # Run after UI tests complete
    if: always() # Run even if UI tests fail
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Install Newman globally
        run: npm install -g newman newman-reporter-htmlextra
        
      - name: Run API tests with Newman
        env:
          NEWMAN_DISABLE_STRICT_SSL: true
        run: |
          echo "Running API tests against demo API (expected to fail for demo purposes)"
          newman run postman/Social-Media-API.postman_collection.json \
            -e postman/Social-Media-API.postman_environment.json \
            --reporters cli,json,htmlextra \
            --reporter-json-export api-test-results.json \
            --reporter-htmlextra-export api-test-report.html \
            --timeout-request 10000 \
            --timeout 30000 \
            --delay-request 100 \
            --color off \
            --insecure
        continue-on-error: true
        
      - name: Upload API test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: api-test-results
          path: |
            api-test-results.json
            api-test-report.html
          retention-days: 14
          
      - name: Display API test summary
        if: always()
        run: |
          echo "## 📡 API Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f api-test-results.json ]; then
            echo "### 📊 Test Execution Details" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            node -e "
              const fs = require('fs');
              if (fs.existsSync('api-test-results.json')) {
                const results = JSON.parse(fs.readFileSync('api-test-results.json', 'utf8'));
                const run = results.run;
                const stats = run.stats;
                
                console.log('| Metric | Value |');
                console.log('|--------|-------|');
                console.log(\`| Total Requests | \${stats.requests.total} |\`);
                console.log(\`| ✅ Passed | \${stats.assertions.total - stats.assertions.failed} |\`);
                console.log(\`| ❌ Failed | \${stats.assertions.failed} |\`);
                console.log(\`| ⏱️ Duration | \${(run.timings.completed - run.timings.started) / 1000}s |\`);
                
                if (stats.assertions.failed > 0) {
                  console.log('\\n### ❌ Failed Assertions');
                  run.executions.forEach(exec => {
                    exec.assertions.forEach(assertion => {
                      if (assertion.error) {
                        console.log(\`- \${exec.item.name}: \${assertion.error.message}\`);
                      }
                    });
                  });
                }
              }
            " >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "📄 **Download the HTML report from artifacts for detailed results**" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **API tests failed to generate results**" >> $GITHUB_STEP_SUMMARY
          fi

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [playwright-tests, api-tests]
    if: always()
    
    steps:
      - name: Generate Overall Summary
        run: |
          echo "# 🎯 Complete Test Suite Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Jobs Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Playwright Tests | ${{ needs.playwright-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| API Tests | ${{ needs.api-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📦 **All test artifacts are available for download above**" >> $GITHUB_STEP_SUMMARY

  allure-report:
    name: 📊 Allure Report
    runs-on: ubuntu-latest
    needs: [playwright-tests]
    if: always()
    permissions:
      contents: write
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          
      - name: Prepare Allure results
        run: |
          mkdir -p allure-results
          # Copy results from both projects
          if [ -d "artifacts/test-results-track-a-instagram/allure-results" ]; then
            cp -r artifacts/test-results-track-a-instagram/allure-results/* allure-results/ || true
          fi
          if [ -d "artifacts/test-results-track-b-mock/allure-results" ]; then
            cp -r artifacts/test-results-track-b-mock/allure-results/* allure-results/ || true
          fi
          
          # Verify results exist
          if [ ! "$(ls -A allure-results)" ]; then
            echo "No Allure results found, creating placeholder"
            echo '{"name":"No tests run","status":"unknown"}' > allure-results/placeholder.json
          fi
          
          ls -la allure-results/
          
      - name: Generate Allure Report
        uses: simple-elf/allure-report-action@master
        with:
          allure_results: allure-results
          allure_report: allure-report
          gh_pages: gh-pages
          allure_history: allure-history
          keep_reports: 20
          
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_branch: gh-pages
          publish_dir: allure-report
          
      - name: Add report link to summary
        run: |
          REPO_NAME="${{ github.event.repository.name }}"
          OWNER="${{ github.repository_owner }}"
          echo "## 📊 Allure Test Report Published" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "🔗 **View Report**: https://${OWNER}.github.io/${REPO_NAME}/" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📅 Updated: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY